# rlberkeley-solutions
My solutions in Julia (Knet and ReinforcementLearning.jl)

Handouts:
1. [HW1](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw1/hw1.pdf)
  . Behavioral Cloning
  . Dagger
2. [HW2](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw2/report/HW2.ipynb)
  . MDP
  . Value Iteration
  . Policy Iteration
3. [HW3](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw3/hw3.pdf)
  . Q Value Approximation
  . Deep Q Network
4. [HW4](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw4/homework.md)
  . Policy Gradient
  . REINFORCE

Reports:
1. [HW1](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw1/report/Report-HW1.ipynb)
2. [HW2](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw2/report/HW2.ipynb)
3. [HW3](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw3/report/Report-HW3.ipynb)
4. [HW4](https://github.com/ozanarkancan/rlberkeley-solutions/blob/master/hw4/report/Report-HW4.ipynb)
